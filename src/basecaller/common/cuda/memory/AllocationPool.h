// Copyright (c) 2019, Pacific Biosciences of California, Inc.
//
// All rights reserved.
//
// THIS SOFTWARE CONSTITUTES AND EMBODIES PACIFIC BIOSCIENCES' CONFIDENTIAL
// AND PROPRIETARY INFORMATION.
//
// Disclosure, redistribution and use of this software is subject to the
// terms and conditions of the applicable written agreement(s) between you
// and Pacific Biosciences, where "you" refers to you or your company or
// organization, as applicable.  Any other disclosure, redistribution or
// use is prohibited.
//
// THIS SOFTWARE IS PROVIDED BY PACIFIC BIOSCIENCES AND ITS CONTRIBUTORS "AS
// IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
// THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
// PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL PACIFIC BIOSCIENCES OR ITS
// CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
// EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
// PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
// OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
// WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR
// OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
// ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

#ifndef PACBIO_CUDA_MEMORY_GPU_POOLED_ALLOCATION_H
#define PACBIO_CUDA_MEMORY_GPU_POOLED_ALLOCATION_H

#include <cassert>
#include <memory>

#include <pacbio/ipc/ThreadSafeQueue.h>
#include <pacbio/PBException.h>

#include "SmartDeviceAllocation.h"
#include "SmartHostAllocation.h"

namespace PacBio {
namespace Cuda {
namespace Memory {

class HostAllocator
{
public:
    explicit HostAllocator(size_t size, bool pinned)
        : size_(size)
        , pinned_(pinned)
    {}

    using Allocation = SmartHostAllocation;

    Allocation Allocate()
    {
        return Allocation(size_, pinned_);
    }

    size_t AllocSize() const { return size_; }

private:
    size_t size_;
    bool pinned_;
};

class DeviceAllocator
{
public:
    explicit DeviceAllocator(size_t size)
        : size_(size)
    {}

    using Allocation = SmartDeviceAllocation;

    Allocation Allocate()
    {
        return Allocation(size_);
    }

    size_t AllocSize() const { return size_; }

private:
    size_t size_;
};

// Just a dumb memory pool, allowing us to re-use allocations.  Should eventually
// be made smarter, at the least so it has a max size, but it's sufficient for now.
template <typename Allocator>
class AllocationPool
{
    using Allocation = typename Allocator::Allocation;
public:
    AllocationPool(const Allocator& allocator, size_t numInitialAllocs = 0)
        : allocator_(allocator)
    {
        for (size_t i = 0; i < numInitialAllocs; ++i)
        {
            allocations_.Push(allocator_.Allocate());
        }
    }

    // Grabs an allocation from the pool, or creates a new one if none available.  Will
    // throw if `size` is inconsistent with how the class was constructed
    Allocation PopAlloc(size_t size)
    {
        if (size!= allocator_.AllocSize()) throw PBException("Bad pooled gpu allocation request");

        Allocation ptr;
        bool found = allocations_.TryPop(ptr);
        if (found) return ptr;
        else return allocator_.Allocate();
    }
    // Puts a pointer back into the memory pool.  *Only* call this with pointers first
    // generated by this pool!
    void PushAlloc(Allocation data)
    {
        if (data.size() != allocator_.AllocSize()) throw PBException("Incorrect length allocation pushed to pool");
        allocations_.Push(std::move(data));
    }

    // Returns the size of allocations used in this pool.  It will *only* generate new
    // allocations of this size, and you should only "push" in allocations of this size
    size_t AllocSize() const { return allocator_.AllocSize(); }

private:
    PacBio::ThreadSafeQueue<Allocation> allocations_;
    Allocator allocator_;
};

using HostAllocationPool = AllocationPool<HostAllocator>;
using GpuAllocationPool = AllocationPool<DeviceAllocator>;

struct DualAllocationPools
{
    DualAllocationPools(size_t allocationSize,
                        bool pinnedHost = true,
                        size_t numInitialHostAllocs = 0,
                        size_t numInitialDeviceAllocs = 0)
        : gpuPool(DeviceAllocator(allocationSize), numInitialDeviceAllocs)
        , hostPool(HostAllocator(allocationSize, pinnedHost), numInitialHostAllocs)
    {}

    GpuAllocationPool gpuPool;
    HostAllocationPool hostPool;
};

}}}

#endif // PACBIO_CUDA_MEMORY_GPU_POOLED_ALLOCATION_H
